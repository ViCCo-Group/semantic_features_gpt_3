{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top features per dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.data import load_dimension_embeddings, load_gpt, load_sorting, load_data\n",
    "from copy import deepcopy\n",
    "from evaluation.correlation import calc_correlation, vectorize_concepts\n",
    "from evaluation.data import load_data, load_gpt, load_cslb, load_sorting, load_cslb_count_vec, load_mcrae, generate_concepts_to_keep, match_behv_sim, load_behav\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort(df):\n",
    "    sorted_df = sorting_df.reset_index().set_index('concept_id')\n",
    "    df['concept_num'] = df.index.map(sorted_df['index'])\n",
    "    df = df.sort_values(by='concept_num')\n",
    "    df = df.drop('concept_num', axis=1)\n",
    "    return df\n",
    "\n",
    "def vec(gpt_df, cslb_df, mc_df, behv_sim, bert_df, vec = 'binary'):\n",
    "    gpt_vec = vectorize_concepts(gpt_df, load_sorting(), 'bla', vec)\n",
    "    cslb_vec = vectorize_concepts(cslb_df, load_sorting(), 'bla', vec)\n",
    "    mc_vec = vectorize_concepts(mc_df, load_sorting(), 'bla', vec)\n",
    "    bert_vec = vectorize_concepts(bert_df, load_sorting(), 'bla', vec)\n",
    "\n",
    "    if vec == 'count':\n",
    "        cslb_vec = load_cslb_count_vec()\n",
    "\n",
    "    intersection_concepts = generate_concepts_to_keep(gpt_df, mc_df, cslb_df, bert_df, 'intersection')\n",
    "    gpt_vec = gpt_vec.loc[intersection_concepts]\n",
    "    cslb_vec = cslb_vec.loc[intersection_concepts]\n",
    "    mc_vec = mc_vec.loc[intersection_concepts]\n",
    "    bert_vec = bert_vec.loc[intersection_concepts]\n",
    "    behv_sim = match_behv_sim(behv_sim, intersection_concepts, load_sorting())\n",
    "    gpt_vec = sort(gpt_vec)\n",
    "    cslb_vec = sort(cslb_vec)\n",
    "    mc_vec = sort(mc_vec)\n",
    "    bert_vec = sort(bert_vec)\n",
    "    \n",
    "    return gpt_vec, cslb_vec, mc_vec, behv_sim, bert_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_amount_runs_feature_occured = 5\n",
    "group_to_one_concept = True\n",
    "min_amount_runs_feature_occured_within_concept = 1\n",
    "run_nr = None \n",
    "duplicates = True \n",
    "strategy = None\n",
    "vec_method = 'count'\n",
    "\n",
    "gpt_df, mc_df, behv_sim, cslb_df, sorting_df = load_data(True, True, min_amount_runs_feature_occured, min_amount_runs_feature_occured_within_concept, strategy, group_to_one_concept, run_nr, duplicates)\n",
    "gpt_vec, cslb_vec, mc_vec, behv_sim = vec(gpt_df, cslb_df, mc_df, behv_sim, vec_method)\n",
    "dimension_embeddings = load_dimension_embeddings()\n",
    "intersection_concepts = generate_concepts_to_keep(gpt_df, mc_df, cslb_df, 'intersection')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = dimension_embeddings.columns\n",
    "dims = dims[:1]\n",
    "for dim in dims:\n",
    "    print(f'Dimension: {dim}')\n",
    "    for model, vec_df in (('GPT', gpt_vec), ('CSLB', cslb_vec)):\n",
    "        print(f'Model: {model}')\n",
    "        vectorized_concepts_copy = deepcopy(vec_df)\n",
    "        # slow\n",
    "        for concept_id in intersection_concepts:\n",
    "            if concept_id != 'man':\n",
    "                dimension_score = dimension_embeddings.loc[concept_id][dim]\n",
    "                vectorized_concepts_copy.loc[concept_id] = vectorized_concepts_copy.loc[concept_id] * dimension_score\n",
    "\n",
    "        vectorized_concepts_sum = vectorized_concepts_copy.sum(axis=0)\n",
    "\n",
    "        #for feature in vectorized_concepts_sum.index:\n",
    "        #    amount_concepts_where_feature_occured = vectorized_concepts[vectorized_concepts[feature] == 1].shape[0]\n",
    "        #    vectorized_concepts_sum[feature] = vectorized_concepts_sum[feature] / amount_concepts_where_feature_occured\n",
    "        dim_string = dim.replace('/', '-')\n",
    "        top_features = vectorized_concepts_sum.sort_values(ascending=False)[:20]\n",
    "        print(top_features)\n",
    "    top_features.to_csv(f'./evaluation/dimensions/{dim_string}.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
