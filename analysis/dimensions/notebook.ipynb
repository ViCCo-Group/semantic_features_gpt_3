{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top features per dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 13:02:37.295387: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-08 13:02:37.295420: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import os \n",
    "\n",
    "sys.path.append('../..')\n",
    "\n",
    "DATA_DIR = '../../data'\n",
    "os.environ['DATA_DIR'] = DATA_DIR\n",
    "\n",
    "from copy import deepcopy\n",
    "from utils.data import load_data, load_dimension_embeddings, load_sorting\n",
    "from utils.correlation import vectorize_concepts\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hannes/anaconda3/envs/features/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "min_amount_runs_feature_occured = 5\n",
    "group_to_one_concept = True\n",
    "min_amount_runs_feature_occured_within_concept = 1\n",
    "run_nr = None \n",
    "duplicates = True \n",
    "gpt_df, mc_df, behv_sim, cslb_df, sorting_df, _ = load_data(True, True, min_amount_runs_feature_occured, min_amount_runs_feature_occured_within_concept, group_to_one_concept, run_nr, duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature-Concept Matrix with TF-IDF \n",
    "\n",
    "normalized across concepts, so that features like is small are weighted less as they are present in almost all concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_vec_count = vectorize_concepts(gpt_df, load_sorting(), 'bla', 'tfidf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature-Concept Matrix with Counts\n",
    "\n",
    "normalized by dividing by the number of concepts the features occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>absorbs water</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amplifies sound</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attracts iron</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attracts metal</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attracts nails</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winks clothes</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winks dishes</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>writes</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>writes on paper</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>writes well</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9508 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "absorbs water    4\n",
       "amplifies sound  4\n",
       "attracts iron    1\n",
       "attracts metal   1\n",
       "attracts nails   1\n",
       "...             ..\n",
       "winks clothes    4\n",
       "winks dishes     1\n",
       "writes           3\n",
       "writes on paper  6\n",
       "writes well      5\n",
       "\n",
       "[9508 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_vec_binary = vectorize_concepts(gpt_df, load_sorting(), 'bla', 'binary')\n",
    "\n",
    "def count_concepts(values):\n",
    "    n = len([value for value in values if value != 0])\n",
    "    return n\n",
    "\n",
    "counts = gpt_vec_binary.groupby(lambda x: True).agg(count_concepts).reset_index(drop=True).T\n",
    "\n",
    "gpt_vec_count = vectorize_concepts(gpt_df, load_sorting(), 'bla', 'count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# when CSLB is used we can only use the overlap concepts\n",
    "#dimension_embeddings = dimension_embeddings.loc[dimension_embeddings.index.isin(intersection_concepts)]\n",
    "\n",
    "list(gpt_vec_binary.index) == list(dimension_embeddings.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def weight_feature_counts_with_dimension_values(df, dimension_values, normalized):\n",
    "#    df = df.mul(dimension_values, axis=0)\n",
    "#    df = df.sum(axis=0).to_frame()\n",
    "\n",
    "#    if normalized:\n",
    "#        df = df.div(counts)\n",
    "        \n",
    "#    df = df.reset_index() \n",
    "#    df = df.rename(columns={df.columns[0]: 'feature', df.columns[1]: 'weight'})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_top_list(df):\n",
    "    df_list = pd.DataFrame()\n",
    "    for dim in df.columns:\n",
    "        dim_values = df.loc[:, [dim]].reset_index()\n",
    "        dim_values = dim_values.rename(columns={dim_values.columns[0]: 'feature', dim_values.columns[1]: 'weight'})\n",
    "        top = dim_values.sort_values(by='weight', ascending=False)[:20]\n",
    "        top['dimension'] = dim\n",
    "        df_list = pd.concat([df_list, top])\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dimension weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49,)\n",
      "(1854, 49)\n"
     ]
    }
   ],
   "source": [
    "normed_features = pd.DataFrame()\n",
    "\n",
    "n_dims = 49\n",
    "dimension_embeddings = load_dimension_embeddings(n_dims)\n",
    "dims = dimension_embeddings.columns\n",
    "\n",
    "# norm sum = 1 per dimension -> needed for normalization by dimensions\n",
    "dim_sums = dimension_embeddings.sum(axis=0)\n",
    "print(dim_sums.shape)\n",
    "dimension_embeddings = dimension_embeddings.div(dim_sums)\n",
    "print(dimension_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rl}\n",
      "\\toprule\n",
      " index &                                        Dimension \\\\\n",
      "\\midrule\n",
      "     1 &                made of metal / artificial / hard \\\\\n",
      "     2 &  food-related / eating-related / kitchen-related \\\\\n",
      "     3 &                         animal-related / organic \\\\\n",
      "     4 &             clothing-related / fabric / covering \\\\\n",
      "     5 & furniture-related / household-related / artifact \\\\\n",
      "     6 &                            plant-related / green \\\\\n",
      "     7 &                                 outdoors-related \\\\\n",
      "     8 &             transportation / motorized / dynamic \\\\\n",
      "     9 &                          wood-related / brownish \\\\\n",
      "    10 &                                body part-related \\\\\n",
      "    11 &                                         colorful \\\\\n",
      "    12 &              valuable / special occasion-related \\\\\n",
      "    13 &                          electronic / technology \\\\\n",
      "    14 &    sport-related / recreational activity-related \\\\\n",
      "    15 &                              disc-shaped / round \\\\\n",
      "    16 &                                     tool-related \\\\\n",
      "    17 &               many small things / course pattern \\\\\n",
      "    18 &       paper-related / thin / flat / text-related \\\\\n",
      "    19 &                    fluid-related / drink-related \\\\\n",
      "    20 &                                      long / thin \\\\\n",
      "    21 &                             water-related / blue \\\\\n",
      "    22 &                     powdery / fine-scale pattern \\\\\n",
      "    23 &                                              red \\\\\n",
      "    24 &          feminine (stereotypically) / decorative \\\\\n",
      "    25 &                      bathroom-related / sanitary \\\\\n",
      "    26 &                                    black / noble \\\\\n",
      "    27 &               weapon / danger-related / violence \\\\\n",
      "    28 &       musical instrument-related / noise-related \\\\\n",
      "    29 &  sky-related / flying-related / floating-related \\\\\n",
      "    30 &     spherical / ellipsoid / rounded / voluminous \\\\\n",
      "    31 &                                       repetitive \\\\\n",
      "    32 &                                 flat / patterned \\\\\n",
      "    33 &                                            white \\\\\n",
      "    34 &                                      thin / flat \\\\\n",
      "    35 &                                disgusting / bugs \\\\\n",
      "    36 &                                   string-related \\\\\n",
      "    37 &                           arms/legs/skin-related \\\\\n",
      "    38 &                              shiny / transparent \\\\\n",
      "    39 &     construction-related / physical work-related \\\\\n",
      "    40 &                      fire-related / heat-related \\\\\n",
      "    41 &                      head-related / face-related \\\\\n",
      "    42 &                                    beams-related \\\\\n",
      "    43 &              seating-related / put things on top \\\\\n",
      "    44 &                       container-related / hollow \\\\\n",
      "    45 &                      child-related / toy-related \\\\\n",
      "    46 &                                 medicine-related \\\\\n",
      "    47 &                                      has grating \\\\\n",
      "    48 &                               handicraft-related \\\\\n",
      "    49 &                            cylindrical / conical \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame({'Dimension': load_dimension_embeddings(49).columns}).reset_index()\n",
    "df['index'] = df['index'] + 1\n",
    "print(df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute dimension weights for all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: made of metal / artificial / hard\n",
      "Dimension: food-related / eating-related / kitchen-related\n",
      "Dimension: animal-related / organic\n",
      "Dimension: clothing-related / fabric / covering\n",
      "Dimension: furniture-related / household-related / artifact\n",
      "Dimension: plant-related / green\n",
      "Dimension: outdoors-related\n",
      "Dimension: transportation / motorized / dynamic\n",
      "Dimension: wood-related / brownish\n",
      "Dimension: body part-related\n",
      "Dimension: colorful\n",
      "Dimension: valuable / special occasion-related\n",
      "Dimension: electronic / technology\n",
      "Dimension: sport-related / recreational activity-related\n",
      "Dimension: disc-shaped / round\n",
      "Dimension: tool-related\n",
      "Dimension: many small things / course pattern\n",
      "Dimension: paper-related / thin / flat / text-related\n",
      "Dimension: fluid-related / drink-related\n",
      "Dimension: long / thin\n",
      "Dimension: water-related / blue\n",
      "Dimension: powdery / fine-scale pattern\n",
      "Dimension: red\n",
      "Dimension: feminine (stereotypically) / decorative\n",
      "Dimension: bathroom-related / sanitary\n",
      "Dimension: black / noble\n",
      "Dimension: weapon / danger-related / violence\n",
      "Dimension: musical instrument-related / noise-related\n",
      "Dimension: sky-related / flying-related / floating-related\n",
      "Dimension: spherical / ellipsoid / rounded / voluminous\n",
      "Dimension: repetitive\n",
      "Dimension: flat / patterned\n",
      "Dimension: white\n",
      "Dimension: thin / flat\n",
      "Dimension: disgusting / bugs\n",
      "Dimension: string-related\n",
      "Dimension: arms/legs/skin-related\n",
      "Dimension: shiny / transparent\n",
      "Dimension: construction-related / physical work-related\n",
      "Dimension: fire-related / heat-related\n",
      "Dimension: head-related / face-related\n",
      "Dimension: beams-related\n",
      "Dimension: seating-related / put things on top\n",
      "Dimension: container-related / hollow\n",
      "Dimension: child-related / toy-related\n",
      "Dimension: medicine-related\n",
      "Dimension: has grating\n",
      "Dimension: handicraft-related\n",
      "Dimension: cylindrical / conical\n"
     ]
    }
   ],
   "source": [
    "weighted_features_for_all_dims = pd.DataFrame()\n",
    "\n",
    "for dim in dims:\n",
    "    print(f'Dimension: {dim}')\n",
    "    df = deepcopy(gpt_vec_count)\n",
    "    dimension_values = dimension_embeddings.loc[:, dim]\n",
    "    df = df.mul(dimension_values, axis=0)\n",
    "    df = df.sum(axis=0).to_frame().sort_index()\n",
    "    df = df.rename(columns={df.columns[0]: dim})\n",
    "    weighted_features_for_all_dims = pd.concat([weighted_features_for_all_dims, df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize feature weights across dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By substract mean value from all other dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in dims:\n",
    "    features_for_all_other_dims = weighted_features_for_all_dims.drop(dim, axis=1)\n",
    "    mean_per_feature = features_for_all_other_dims.mean(axis=1)\n",
    "\n",
    "    dim_values = weighted_features_for_all_dims.loc[:, dim]\n",
    "    dim_values_normed = dim_values.subtract(mean_per_feature).to_frame()\n",
    "\n",
    "    dim_values_normed = dim_values_normed.rename(columns={dim_values_normed.columns[0]: dim})\n",
    "    normed_features = pd.concat([normed_features, dim_values_normed], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_features.to_csv(f'./normed_features_per_{n_dims}_dimension_matrix.csv')\n",
    "matrix_to_top_list(normed_features).to_csv(f'./normed_features_per_{n_dims}_dimension_list.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69bbc8a61151a626d9131c945f79b1d3b7a273f7c9919d5e4680ea5234d3a94f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('features': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
